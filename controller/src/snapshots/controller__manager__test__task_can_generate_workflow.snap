---
source: controller/src/manager.rs
expression: "&wf"
---
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  labels:
    ame-task: training
  name: training
  ownerReferences:
    - apiVersion: ""
      kind: ""
      name: ""
      uid: ""
spec:
  entrypoint: main
  templates:
    - name: main
      metadata:
        labels: ~
        annotations: ~
      steps:
        - - name: setup
            inline:
              name: setup
              metadata:
                labels:
                  ame-task: training
                annotations: ~
              steps: ~
              securityContext:
                fsGroup: 2000
                runAsUser: 1001
              script:
                command:
                  - bash
                env:
                  - name: AWS_ACCESS_KEY_ID
                    valueFrom:
                      secretKeyRef:
                        key: MINIO_ROOT_USER
                        name: ame-minio-secret
                        optional: false
                  - name: AWS_SECRET_ACCESS_KEY
                    valueFrom:
                      secretKeyRef:
                        key: MINIO_ROOT_PASSWORD
                        name: ame-minio-secret
                        optional: false
                  - name: MLFLOW_TRACKING_URI
                    value: "http://mlflow.default.svc.cluster.local:5000"
                  - name: MINIO_URL
                    value: "http://ame-minio.ame-system.svc.cluster.local:9000"
                  - name: PIPENV_YES
                    value: "1"
                image: "ghcr.io/teainspace/ame/ame-executor:0.0.3"
                name: ""
                resources: {}
                volumeMounts:
                  - mountPath: /project
                    name: training-volume
                source: "\n            s3cmd --no-ssl --region eu-central-1 --host=$MINIO_URL --host-bucket=$MINIO_URL get --recursive s3://ame/tasks/mydataset/artifacts/path_to_data ./\n\n                \n\n            s3cmd --no-ssl --region eu-central-1 --host=$MINIO_URL --host-bucket=$MINIO_URL get --recursive s3://ame/tasks/training/projectfiles/ ./\n\n                       echo \"0\" >> exit.status\n                        "
              podSpecPatch: ~
        - - name: main
            inline:
              name: training
              metadata:
                labels:
                  ame-task: training
                annotations: ~
              steps: ~
              securityContext:
                fsGroup: 2000
                runAsUser: 1001
              script:
                command:
                  - bash
                env:
                  - name: AWS_ACCESS_KEY_ID
                    valueFrom:
                      secretKeyRef:
                        key: MINIO_ROOT_USER
                        name: ame-minio-secret
                        optional: false
                  - name: AWS_SECRET_ACCESS_KEY
                    valueFrom:
                      secretKeyRef:
                        key: MINIO_ROOT_PASSWORD
                        name: ame-minio-secret
                        optional: false
                  - name: MLFLOW_TRACKING_URI
                    value: "http://mlflow.default.svc.cluster.local:5000"
                  - name: MINIO_URL
                    value: "http://ame-minio.ame-system.svc.cluster.local:9000"
                  - name: PIPENV_YES
                    value: "1"
                  - name: KEY1
                    valueFrom:
                      secretKeyRef:
                        key: secret
                        name: secret1
                  - name: KEY2
                    valueFrom:
                      secretKeyRef:
                        key: secret
                        name: secret2
                  - name: VAR1
                    value: val1
                  - name: VAR2
                    value: val2
                image: "ghcr.io/teainspace/ame/ame-executor:0.0.3"
                name: ""
                resources: {}
                volumeMounts:
                  - mountPath: /project
                    name: training-volume
                source: "\n          set -e # It is important that the workflow exits with an error code if execute or save_artifacts fails, so AME can take action based on that information.\n\n          \n                pipenv sync\n\n                pipenv run python train.py\n\n                save_artifacts ame/tasks/training/artifacts/\n\n          echo \"0\" >> exit.status\n            "
              podSpecPatch: "{\"containers\":[{\"name\":\"main\", \"resources\":{\"limits\":null}}]}"
      securityContext: ~
      script: ~
      podSpecPatch: ~
  imagePullSecrets: ~
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: training-volume
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi
      status: {}
  volumes: ~
  serviceAccountName: ame-task

