{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AME","text":""},{"location":"#what-is-ame","title":"What is AME?","text":"<p>AME(Artificial MLOps Engineer) automates operations for the entire model life cycle from early experimentation to deploying models for inferece.</p> <p>AME abstracts away details regarding infrastructure allowing data scientists to focus on datascience.</p> <p>Getting a project started with AME can be as simple as:</p> <pre><code>ame init myproject\name add task training\name task run training\n</code></pre>"},{"location":"#how-does-ame-differ-from-existing-mlops-tools","title":"How does AME differ from existing MLOps tools?","text":""},{"location":"#why-ame","title":"Why AME?","text":""},{"location":"developer_manual/developer/","title":"Working on AME","text":""},{"location":"developer_manual/developer/#writing-documentation","title":"Writing documentation","text":"<p>AME uses mkdocs and mkdocs-material. All the docs are written in markdown and are located under /ame.</p> <p>To start working on the documentation run <code>cd ame &amp;&amp; mkdocs serve</code>.</p>"},{"location":"getting_started/0_quick_start/","title":"Quick Start","text":"<p>This page will get a basic Kubernets and AME setup deployed with minimal effort.</p> <p>If you want skip setting up your own instance, we provide a test instance behind Github login here.</p>"},{"location":"getting_started/0_quick_start/#kubernetes","title":"Kubernetes","text":"<p>There are a number of options for deploying a local cluster. The AME repository contains bootstrapping scripts for the most common options. If you already have a cluster skip to the next step. If you are looking to deploy a to the cloud see this.</p>"},{"location":"getting_started/0_quick_start/#deploying-ame","title":"Deploying AME","text":"<p>AME distributed as a helm chart. Add the helm repository and install the chart. </p> <p><pre><code>helm add ...\nhelm install ...\n</code></pre> For a testing instance the defaults should be adequate. By default a minio instance will be included for object storage.</p> <p>Keycload can be included for for user managment and authentication.</p> <pre><code>helm install ...withkeycloak\n</code></pre>"},{"location":"getting_started/0_quick_start/#first-time-setup","title":"First time setup","text":"<p>To get started we can configure AME either through the CLI, CLI or declaratively with a config map in the cluster. We will use the CLI.</p> <p>Start by connecting the CLI to the new instance.</p> <pre><code>ame connect http://localhost:8003\n</code></pre> <p>*Note that the port might be different, this will be evident in the helm chart output. On the first connect the CLI will check for any issues in the setup. For example if there is no available object storage. There should be no issues to report at this point, otherwise please make an issue or ask a question here.</p> <p>If you think something has gone wrong you can always run <code>ame admin check</code> and AME will report any issues. The dashboard will also make it clear if there is any any need to take action.</p> <p>Now you are all setup to go through the walkthrough. If you have any questons or problem don't hestitate to ask. TODO where?</p>"},{"location":"getting_started/walkthrough/0_introduction/","title":"Introduction","text":"<p>AME is an MLOps platform built around Kubernetes. Although as a user you should not have to interact with Kubernetes directly or now anything about Kubernetes. We highlight the fact since it provides a number of advantages. AME can be deployed anywhere Kubnerets can, which essentially means everywhere from onprem self managed to  a fully managed Kubernetes solution in the cloud. It also means that AME can easily pull in different opensource components to expand functionality as needed. For example we use Argo workflows as the underlying worflow engine and mlfow as a model registry.</p> <p>For administrators of AME it means that all of the existing Kubernetes knowlegde and tooling still applies and AME can be managed just like any other Kubernetes depoyment.</p> <p>It also means that there is a non trivial amount of complexity invovled with standing up an AME instance and managing it, as you inhereit all of the complexities introduced by Kubernetes. In many cases this is not a problem as even without Kubernetes you would need to deal with the same problems. However for simpler cases where a small team just wants som job scheduling for automatic training Kubernetes introduced a lot of overhead. Especially if no one on the team is familiar with Kuberenetes. For now we can not do much about, as we are focusing on production setups where Kubernetes is perfectly justifyable. However it is the goal to decouple AME from kubnernetes, which will allow for simple setups as well.  </p> <p>This section will take your for a practical tour of what AME's features with practical examples. The user guide will go more indepth on user facing topics and the [operator manual] goes indepth on deploying and administrating AME.</p> <p>We have an examples directory with examples of TODO </p>"},{"location":"getting_started/walkthrough/1_run_a_task/","title":"Running a Task with the CLI","text":"<p>This example will introduce to Tasks and the CLI. The complete project is also available in the examples directory.</p> <p>If you followed the quick start your CLI should be connected to an AME instance. If in doubt run <code>ame check</code> and any issues will be reported.</p>"},{"location":"getting_started/walkthrough/1_run_a_task/#your-first-task","title":"Your first Task","text":"<p>Before we can run a task we must have a project setup. To init a project follow the commands as shown below, replacing myproject with the  path to your project.</p> <pre><code>mkdir myproject\ncd myproject\name init\n</code></pre> <p>Now you should have an AME file ame.yaml inside your project: <pre><code>name: myproject\n</code></pre></p> <p>Update your file to match the changes shown below.</p> <pre><code>name: myproject\ntasks:\n- name: hello\n!custom\nexecutor:\npythonVersion: 3.11\ncommand: python hellow_world.py\n</code></pre> <p>and create a python file: <pre><code># hello_world.py\nprint(\"Hello World\")\n</code></pre></p> <p>To run this and see the output use <code>ame task run hello --logs</code>, this will execute the Task remotely and follow the logs in your terminal. If you go the the AME dashboard you can see the Task and logs under ... TODO.</p> <p>Note that we are using the custom executor here as there are no dependencies for AME to install, otherwise we would use an executor for the dependency manager used in our project.  Every Task must have an executor otherwise AME has no idea how to execute it.</p>"},{"location":"operator_manual/deploy-ame/","title":"Deploying AME","text":"<p>This page contains everything you need to know to deploy and administrate AME.</p> <p>If you are looking to try out AME quickly see the quick start.</p> <p>For production installations you are in the right place.</p>"},{"location":"operator_manual/deploy-ame/#installation","title":"Installation","text":"<p>AME offers helm and kustomize options for deployment. If you managing AME via gitops vi recommend that you take the release manifests and copy them into you repository.</p> <p>See the helm chart here and kustomize instructions here.</p>"},{"location":"operator_manual/deploy-ame/#environment-specific-details","title":"Environment specific details","text":""},{"location":"operator_manual/deploy-ame/#gcp","title":"GCP","text":""},{"location":"operator_manual/deploy-ame/#azure","title":"Azure","text":""},{"location":"operator_manual/deploy-ame/#aws","title":"AWS","text":""},{"location":"operator_manual/deploy-ame/#barebones-k8s","title":"Barebones K8S","text":""},{"location":"operator_manual/deploy-ame/#security","title":"Security","text":""},{"location":"operator_manual/deploy-ame/#monitoring-ame","title":"Monitoring AME","text":""},{"location":"operator_manual/deploy-ame/#alerts","title":"Alerts","text":""},{"location":"operator_manual/deploy-ame/#configuring-ame","title":"Configuring AME","text":""},{"location":"operator_manual/deploy-ame/#updating-ame","title":"Updating AME","text":""},{"location":"operator_manual/upgrading/","title":"Upgrading AME","text":""},{"location":"operator_manual/configuration/0_configuring_ame/","title":"Configuring AME","text":"<p>AME attempts to keep configuration in a single config map, which both the server and controller will read from.  There options are then exposed via helm and kustomize as well. This page will walk through AME configuration options.</p> <p>Note that AME has a top down configuration approach, where cluster wide defaults are set in the in the config map, project wide defaults are  set on a per project basis.</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#default-ingress","title":"Default ingress","text":"<p>If you are deploying models it is important to set a default ingress as AME can not yet generate a good default.</p> <p>This is set like ... TODO</p> <p>Options for other ingress than nginx?</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#namespace","title":"Namespace","text":"<p>AME operates within a single namespace, this defaults to ame-system. To override this ... TODO</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#task-service-account","title":"Task service account","text":"<p>AME uses a service account for Tasks with minimal permissions. By default this is <code>ame-task</code>, to override this ... TODO</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#default-images","title":"Default images","text":"<p>AME provides a number of images with good defaults for exeuting Tasks and deploying models. These can all be overridden ... TODO</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#object-storage","title":"Object storage","text":"<p>AME uses object storage to store and cache various files. There are a number of config options that can be set here. For example if you don't want object storage deployed a long side ame but separate from the cluster.</p> <p>TODO how?</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#opentelemtry","title":"Opentelemtry","text":"<p>TODO</p>"},{"location":"operator_manual/configuration/0_configuring_ame/#logs","title":"Logs","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#mlflow","title":"Mlflow","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#keycloak","title":"keycloak","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#argo-workflows","title":"Argo Workflows","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#promethus","title":"Promethus","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#controller-specifics","title":"Controller specifics","text":""},{"location":"operator_manual/configuration/0_configuring_ame/#server-specifics","title":"Server specifics","text":""},{"location":"operator_manual/configuration/kubernetes/","title":"Kubernetes","text":""},{"location":"operator_manual/configuration/kubernetes/#auto-scaling","title":"Auto scaling","text":""},{"location":"user_guide/0_introduction/","title":"Introduction","text":"<p>This page will introduce you to the core concepts in AME.</p>"},{"location":"user_guide/0_introduction/#core-concepts","title":"Core concepts","text":"<p>AME provides a number of simple building blocks which can be used in isolation for simple workflows or combined for more complex requirements.</p> <p>TODO: reformulate this</p>"},{"location":"user_guide/0_introduction/#tasks","title":"Tasks","text":"<p>Note: that yaml configuraion files are used here as a way to easily show different configurations. the CLI and dashboard  will help du generate, edit and valdidate these files so you don't have write mountains of error prone YAML by hand :).</p> <p>A 'Task' is the fundamental unit of work in AME. It can be as simple as running a single command <code>python train.py</code>:</p> <pre><code>project: logreg\ntasks:\n- name: train\nexecutor:\n!pip\npythonVersion: 3.11\ncommand: python train\n</code></pre> <p>or more complex such as orchestrating a pipline or DAG with many sub tasks:</p> <pre><code>project: logreg\ntasks:\n- name: train\npipeline:\n- name: prepare-data\nexecutor:\n!poetry\ncommand: python prepare_data.py\n- name: train\nexecutor:\n!poetry\ncommand: python train.py\nresources:\ncpu: 4\nnvidia.com/gpu: 2\nmemory: 20Gi\nstorage: 100Gi\n- name: save\nexecutor:\n!poetry\ncommand: python save_model.py\n</code></pre> <p>Task's also have a notion of dependencies where a <code>Task</code> can depend on a <code>Dataset</code>. Indicating dependencies  too AME allows for more efficient scheduling of Tasks and caching to avoid repeating the same work. Task's are designed to be able to execute most python projects out of the box. If you have start building custom docker images in day to day usage, that is considered a failure on our part and please submit an issue.</p> <p>We can't cover every possible case therefore if any of the defaults are unssuitable there are escape hatches to allow for things such as custom container images, custom setup commands and patching the underlying K8S resources. This should be a last resort, if you find yourself doing this feel free to submit an issue and we probably expand AME to cover your usecase properly :)</p>"},{"location":"user_guide/0_introduction/#projects","title":"Projects","text":"<p>Projects a specific directory and often repostiory. It provides the context for which Tasks are executed within. The AME file <code>ame.yaml</code> servers as a declaractive way of defining any configuration related to a specific project. This includes Tasks, TaskTemplates, DataSets, Models and project wide defaults.</p>"},{"location":"user_guide/0_introduction/#project-source","title":"Project Source","text":"<p>A project source Tells AME where to look for projects. Currently only Git repositories are supported as projet sources.</p> <p>A typical project source object looks like this:</p> <pre><code>gitProjectSource:\nrepository: github.com/my/ml/repo\nusername: jane\nsecret: reference_to_secret\n</code></pre> <p>AME will then watch every branch on this repo for project files and pull them into the AME cluster.</p>"},{"location":"user_guide/0_introduction/#datasets","title":"DataSets","text":"<p>A <code>DataSet</code> is essentially a <code>Task</code> with extra semantics. Where artifacts generated by the underlying <code>Task</code> are treated as a dataset to be consumed by <code>Tasks</code>. Currently this doesn't add muc. In the future this will allow AME to perform better scheduling. The main advantage right now is that a <code>Task</code> can depend on a <code>DataSet</code> and once a <code>DataSet</code> is cached the work will not be  repeated. Therefore many <code>Tasks</code> can depend on the same DataSet an the dataset will only be generated once. </p> <p>Example dataset</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\n#    task:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre>"},{"location":"user_guide/0_introduction/#models","title":"Models","text":"<p>A <code>Model</code> defines how to train, validate and deploy a machine learning model. All you have to do is tell AME how to train and validate your model in the form of <code>Tasks</code> and then then lifecycle of a model can be automated. AME currently does not have it's own model registry but instead integrates with an mlflow.</p>"},{"location":"user_guide/datasets/","title":"Data Sets","text":"<p>In the simplest form a data set is just a Task which produces data a long with a storage mechanism. This allows for a number of benefits over just using tasks directly. Data can be produced once and used many times. For example if a number of <code>Tasks</code> depend of the same Dataset AME can prepare the dataset once.</p> <p>Here is an example of what a simple data set configuration looks like:</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\n#    task:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre>"},{"location":"user_guide/datasets/#configuring-a-data-set","title":"Configuring a data set","text":"<p>A simple data set cfg is quick to set and can then be progressively enhanced as your needs expand. Here we will walk through the process of first setting up a simple data set and then go through the more advanced options.</p> <p>The minimum requirements for a dataset is a <code>path</code> pointer to where data should be saved from and a <code>Task</code> which will produce data at that path. As shown in the mnist example above. Lets start with that here:</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\ntask:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre> <p>So far so good, we have a path <code>data</code> and reference a <code>Task</code> that produces our data.</p>"},{"location":"user_guide/datasets/#dataset-size","title":"Dataset size","text":"<p>If a dataset is large it is a good idea to specifiy the storage requirements. This will allow AME to warn you if the object storage is running out.</p> <p>If you do not specify the size AME will attempt to save the dataset, detect the failure and then produce an alert.</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\nsize: 50Gi\ntask:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre>"},{"location":"user_guide/datasets/#interacting-with-data-sets","title":"Interacting with data sets","text":"<p>To see the status of live data sets, use the AME's cli. Current it is only possible to see data sets that are in use, meaning referenced by some running task.</p> <pre><code>ame dataset list\name ds list # or shortend\n</code></pre> <p>You can also view datasets from AME's dashboard:</p> <p>TODO: dataset image</p>"},{"location":"user_guide/datasets/#consuming-data-from-object-storage","title":"Consuming data from object storage","text":"<p>AME does not yet have builtin support for extracing data from object storage, although it will in the near future, see the tracking issue here.  It is still quite simplte to accomplish this in pure python, so we shall demonstrate that here.</p>"},{"location":"user_guide/fields/","title":"Protocol Documentation","text":""},{"location":"user_guide/fields/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>lib/ame.proto</p> <ul> <li>AmeSecret</li> <li>AmeSecretId</li> <li>AmeSecretVariant</li> <li>AmeSecrets</li> <li>ArtifactCfg</li> <li>CreateProjectRequest</li> <li>CustomExecutor</li> <li>DataSetCfg</li> <li>Empty</li> <li>EnvVar</li> <li>FileChunk</li> <li>GitProjectSource</li> <li>ListProjectSrcsResponse</li> <li>ListTasksRequest</li> <li>ListTasksResponse</li> <li>ListTasksResponse.TasksEntry</li> <li>LogEntry</li> <li>MlflowExecutor</li> <li>Model</li> <li>ModelDeploymentCfg</li> <li>ModelDeploymentCfg.IngressAnnotationsEntry</li> <li>ModelDeploymentCfg.ResourcesEntry</li> <li>ModelStatus</li> <li>ModelTrainingCfg</li> <li>PipEnvExecutor</li> <li>PipExecutor</li> <li>PoetryExecutor</li> <li>ProjectCfg</li> <li>ProjectFileChunk</li> <li>ProjectFileIdentifier</li> <li>ProjectId</li> <li>ProjectSourceCfg</li> <li>ProjectSourceId</li> <li>ProjectSourceIssue</li> <li>ProjectSourceListParams</li> <li>ProjectSourceStatus</li> <li>ProjectSrcIdRequest</li> <li>ProjectSrcPatchRequest</li> <li>ProjectStatus</li> <li>ProjectStatus.ModelsEntry</li> <li>RemoveTaskRequest</li> <li>ResourceCfg</li> <li>ResourceId</li> <li>ResourceIds</li> <li>ResourceListParams</li> <li>RunTaskRequest</li> <li>Secret</li> <li>TaskCfg</li> <li>TaskCfg.ResourcesEntry</li> <li>TaskId</li> <li>TaskIdentifier</li> <li>TaskListEntry</li> <li>TaskLogRequest</li> <li>TaskPhaseFailed</li> <li>TaskPhasePending</li> <li>TaskPhaseRunning</li> <li>TaskPhaseSucceeded</li> <li>TaskProjectDirectoryStructure</li> <li>TaskRef</li> <li>TaskStatus</li> <li>TemplateRef</li> <li>TrainRequest</li> <li> <p>TriggerCfg</p> </li> <li> <p>ProjectSourceIssueType</p> </li> <li>ProjectSourceState</li> <li> <p>TaskType</p> </li> <li> <p>AmeService</p> </li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"user_guide/fields/#libameproto","title":"lib/ame.proto","text":""},{"location":"user_guide/fields/#amesecret","title":"AmeSecret","text":"<p>This is a secret stored by AME</p> Field Type Label Description key string value string <p></p>"},{"location":"user_guide/fields/#amesecretid","title":"AmeSecretId","text":"Field Type Label Description key string"},{"location":"user_guide/fields/#amesecretvariant","title":"AmeSecretVariant","text":"Field Type Label Description key string injectAs string"},{"location":"user_guide/fields/#amesecrets","title":"AmeSecrets","text":"Field Type Label Description secrets AmeSecretId repeated"},{"location":"user_guide/fields/#artifactcfg","title":"ArtifactCfg","text":"Field Type Label Description save_changed_files bool paths string repeated"},{"location":"user_guide/fields/#createprojectrequest","title":"CreateProjectRequest","text":"Field Type Label Description cfg ProjectCfg enableTriggers bool optional"},{"location":"user_guide/fields/#customexecutor","title":"CustomExecutor","text":"Field Type Label Description pythonVersion string command string"},{"location":"user_guide/fields/#datasetcfg","title":"DataSetCfg","text":"Field Type Label Description name string task TaskCfg path string size string optional"},{"location":"user_guide/fields/#empty","title":"Empty","text":""},{"location":"user_guide/fields/#envvar","title":"EnvVar","text":"Field Type Label Description key string val string"},{"location":"user_guide/fields/#filechunk","title":"FileChunk","text":"Field Type Label Description contents bytes"},{"location":"user_guide/fields/#gitprojectsource","title":"GitProjectSource","text":"Field Type Label Description repository string username string optional secret string optional sync_interval string optional"},{"location":"user_guide/fields/#listprojectsrcsresponse","title":"ListProjectSrcsResponse","text":"Field Type Label Description cfgs ProjectSourceCfg repeated"},{"location":"user_guide/fields/#listtasksrequest","title":"ListTasksRequest","text":""},{"location":"user_guide/fields/#listtasksresponse","title":"ListTasksResponse","text":"Field Type Label Description tasks ListTasksResponse.TasksEntry repeated"},{"location":"user_guide/fields/#listtasksresponsetasksentry","title":"ListTasksResponse.TasksEntry","text":"Field Type Label Description key string value TaskListEntry"},{"location":"user_guide/fields/#logentry","title":"LogEntry","text":"Field Type Label Description contents bytes"},{"location":"user_guide/fields/#mlflowexecutor","title":"MlflowExecutor","text":""},{"location":"user_guide/fields/#model","title":"Model","text":"Field Type Label Description name string validationTask TaskCfg optional training ModelTrainingCfg optional deployment ModelDeploymentCfg optional"},{"location":"user_guide/fields/#modeldeploymentcfg","title":"ModelDeploymentCfg","text":"Field Type Label Description ingressAnnotations ModelDeploymentCfg.IngressAnnotationsEntry repeated replicas int32 optional image string optional resources ModelDeploymentCfg.ResourcesEntry repeated enableTls bool optional"},{"location":"user_guide/fields/#modeldeploymentcfgingressannotationsentry","title":"ModelDeploymentCfg.IngressAnnotationsEntry","text":"Field Type Label Description key string value string"},{"location":"user_guide/fields/#modeldeploymentcfgresourcesentry","title":"ModelDeploymentCfg.ResourcesEntry","text":"Field Type Label Description key string value string"},{"location":"user_guide/fields/#modelstatus","title":"ModelStatus","text":"Field Type Label Description latestValidatedModelVersion string optional"},{"location":"user_guide/fields/#modeltrainingcfg","title":"ModelTrainingCfg","text":"Field Type Label Description task TaskCfg"},{"location":"user_guide/fields/#pipenvexecutor","title":"PipEnvExecutor","text":"Field Type Label Description command string"},{"location":"user_guide/fields/#pipexecutor","title":"PipExecutor","text":"Field Type Label Description pythonVersion string command string"},{"location":"user_guide/fields/#poetryexecutor","title":"PoetryExecutor","text":"Field Type Label Description pythonVersion string command string"},{"location":"user_guide/fields/#projectcfg","title":"ProjectCfg","text":"Field Type Label Description name string models Model repeated dataSets DataSetCfg repeated tasks TaskCfg repeated templates TaskCfg repeated enableTriggers bool optional"},{"location":"user_guide/fields/#projectfilechunk","title":"ProjectFileChunk","text":"Field Type Label Description chunk FileChunk identifier ProjectFileIdentifier"},{"location":"user_guide/fields/#projectfileidentifier","title":"ProjectFileIdentifier","text":"Field Type Label Description taskid string filepath string"},{"location":"user_guide/fields/#projectid","title":"ProjectId","text":"Field Type Label Description name string"},{"location":"user_guide/fields/#projectsourcecfg","title":"ProjectSourceCfg","text":"Field Type Label Description git GitProjectSource optional"},{"location":"user_guide/fields/#projectsourceid","title":"ProjectSourceId","text":"Field Type Label Description name string"},{"location":"user_guide/fields/#projectsourceissue","title":"ProjectSourceIssue","text":"Field Type Label Description issue_type ProjectSourceIssueType explanation string optional"},{"location":"user_guide/fields/#projectsourcelistparams","title":"ProjectSourceListParams","text":""},{"location":"user_guide/fields/#projectsourcestatus","title":"ProjectSourceStatus","text":"Field Type Label Description last_synced string optional state ProjectSourceState reason string optional issues ProjectSourceIssue repeated"},{"location":"user_guide/fields/#projectsrcidrequest","title":"ProjectSrcIdRequest","text":"Field Type Label Description repo string"},{"location":"user_guide/fields/#projectsrcpatchrequest","title":"ProjectSrcPatchRequest","text":"Field Type Label Description id ProjectSourceId cfg ProjectSourceCfg"},{"location":"user_guide/fields/#projectstatus","title":"ProjectStatus","text":"Field Type Label Description models ProjectStatus.ModelsEntry repeated"},{"location":"user_guide/fields/#projectstatusmodelsentry","title":"ProjectStatus.ModelsEntry","text":"Field Type Label Description key string value ModelStatus"},{"location":"user_guide/fields/#removetaskrequest","title":"RemoveTaskRequest","text":"Field Type Label Description name string approve bool optional"},{"location":"user_guide/fields/#resourcecfg","title":"ResourceCfg","text":"Field Type Label Description projectSrcCfg ProjectSourceCfg"},{"location":"user_guide/fields/#resourceid","title":"ResourceId","text":"Field Type Label Description projectSrcId ProjectSourceId"},{"location":"user_guide/fields/#resourceids","title":"ResourceIds","text":"Field Type Label Description ids ResourceId repeated"},{"location":"user_guide/fields/#resourcelistparams","title":"ResourceListParams","text":"Field Type Label Description projectSourceListParams ProjectSourceListParams"},{"location":"user_guide/fields/#runtaskrequest","title":"RunTaskRequest","text":"Field Type Label Description projectId ProjectId taskCfg TaskCfg"},{"location":"user_guide/fields/#secret","title":"Secret","text":"Field Type Label Description ame AmeSecretVariant"},{"location":"user_guide/fields/#taskcfg","title":"TaskCfg","text":"Field Type Label Description name string optional taskRef TaskRef optional resources TaskCfg.ResourcesEntry repeated poetry PoetryExecutor mlflow MlflowExecutor pipEnv PipEnvExecutor pip PipExecutor custom CustomExecutor dataSets string repeated fromTemplate TemplateRef optional artifactCfg ArtifactCfg optional triggers TriggerCfg optional env EnvVar repeated secrets Secret repeated"},{"location":"user_guide/fields/#taskcfgresourcesentry","title":"TaskCfg.ResourcesEntry","text":"Field Type Label Description key string value string"},{"location":"user_guide/fields/#taskid","title":"TaskId","text":"Field Type Label Description name string"},{"location":"user_guide/fields/#taskidentifier","title":"TaskIdentifier","text":"Field Type Label Description name string"},{"location":"user_guide/fields/#tasklistentry","title":"TaskListEntry","text":"Field Type Label Description status TaskStatus timeStamp string"},{"location":"user_guide/fields/#tasklogrequest","title":"TaskLogRequest","text":"Field Type Label Description taskid TaskIdentifier start_from int32 optional watch bool optional"},{"location":"user_guide/fields/#taskphasefailed","title":"TaskPhaseFailed","text":"Field Type Label Description workflowName string"},{"location":"user_guide/fields/#taskphasepending","title":"TaskPhasePending","text":""},{"location":"user_guide/fields/#taskphaserunning","title":"TaskPhaseRunning","text":"Field Type Label Description workflowName string"},{"location":"user_guide/fields/#taskphasesucceeded","title":"TaskPhaseSucceeded","text":"Field Type Label Description workflowName string"},{"location":"user_guide/fields/#taskprojectdirectorystructure","title":"TaskProjectDirectoryStructure","text":"Field Type Label Description projectid string taskid TaskIdentifier paths string repeated"},{"location":"user_guide/fields/#taskref","title":"TaskRef","text":"Field Type Label Description name string project string optional"},{"location":"user_guide/fields/#taskstatus","title":"TaskStatus","text":"<p>TODO: should there be an error case?</p> Field Type Label Description pending TaskPhasePending running TaskPhaseRunning failed TaskPhaseFailed succeeded TaskPhaseSucceeded <p></p>"},{"location":"user_guide/fields/#templateref","title":"TemplateRef","text":"Field Type Label Description name string project string optional"},{"location":"user_guide/fields/#trainrequest","title":"TrainRequest","text":"Field Type Label Description projectid string model_name string"},{"location":"user_guide/fields/#triggercfg","title":"TriggerCfg","text":"Field Type Label Description schedule string optional"},{"location":"user_guide/fields/#projectsourceissuetype","title":"ProjectSourceIssueType","text":"Name Number Description Unknown 0 AuthFailure 1 RepositoryNotFound 2 AmeProjectNotFound 3 GitSecretNotFound 4"},{"location":"user_guide/fields/#projectsourcestate","title":"ProjectSourceState","text":"Name Number Description Pending 0 Synchronising 1 Synchronized 2 Error 3"},{"location":"user_guide/fields/#tasktype","title":"TaskType","text":"Name Number Description Pipenv 0 Mlflow 1 Poetry 2"},{"location":"user_guide/fields/#ameservice","title":"AmeService","text":"Method Name Request Type Response Type Description RunTask RunTaskRequest TaskIdentifier GetTask TaskIdentifier TaskCfg DeleteTask TaskIdentifier Empty CreateTaskProjectDirectory TaskProjectDirectoryStructure Empty UploadProjectFile ProjectFileChunk stream Empty StreamTaskLogs TaskLogRequest LogEntry stream CreateProjectSrc ProjectSourceCfg ProjectSourceId DeleteProjectSrc ProjectSourceId Empty TrainModel TrainRequest Empty WatchProjectSrc ProjectSourceId ProjectSourceStatus stream CreateSecret AmeSecret Empty DeleteSecret AmeSecretId Empty ListSecrets Empty AmeSecrets UpdateProjectSrc ProjectSrcPatchRequest Empty CreateResource ResourceCfg ResourceId ListResource ResourceListParams ResourceIds GetProjectSrcCfg ProjectSourceId ProjectSourceCfg GetProjectSrcStatus ProjectSourceId ProjectSourceStatus GetProjectSrcId ProjectSrcIdRequest ProjectSourceId ListProjectSrcs ProjectSourceListParams ListProjectSrcsResponse CreateProject CreateProjectRequest ProjectId ListTasks ListTasksRequest ListTasksResponse RemoveTask RemoveTaskRequest Empty"},{"location":"user_guide/fields/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"},{"location":"user_guide/model_validation/","title":"Guides","text":"<p>This page provides in depths tutorials for AME. If you are looking to quickly try out AME, see getting started.</p>"},{"location":"user_guide/model_validation/#from-zero-to-live-model","title":"From zero to live model","text":"<p>This guide is focused on using AME if you are looking for a deployment guide go here.</p> <p>This guide will walk through going from zero to having a model served through an the V2 inference protocol. it will be split into multiple sub steps which can be consumed in isolation if you are just looking for a smaller guide on that specific step.</p> <p>Almost any python project should be usable but if you want to follow along with the exact same project as the guide clone this repo.</p>"},{"location":"user_guide/model_validation/#setup-the-cli","title":"Setup the CLI","text":"<p>Before we can initialise an AME project we need to install the ame CLI and connect with your AME instance.</p> <p>TODO describe installation</p>"},{"location":"user_guide/model_validation/#initialising-ame-in-your-project","title":"Initialising AME in your project","text":"<p>The first step will be creating an <code>ame.yaml</code> file in the project directory.</p> <p>This is easiet to do with the ame CLI by running <code>ame project init</code>. The CLI will ask for a project and then produce a file that looks like this:</p> <pre><code>name: sklearn_logistic_regression\n</code></pre>"},{"location":"user_guide/model_validation/#the-first-training","title":"The first training","text":"<p>Next we want to set up our model to be run by AME. The most important thing here is the Task that will train the model so lets start with that.</p> <p>Here we need to consider a few things, what command is used to train a model, how are dependencies managed in our project, what python version do we need and how many resources does our model training require.</p> <p>If you are using the repo for this guide, you will want a task configured as below. </p> <pre><code>name: sklearn_logistic_regression\ntasks:\n- name: training\n!poetry\nexecutor:\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>To try out our task we can run <code>ame task run training --logs</code> and see the task get deployed and executed.</p> <p>For model specific features such validation and deployment we want to declare a model in our AME file.</p> <p>We add a simple model called logreg and specify the training task. This will allow AME to automatically train new model versions when appropriate.</p> <pre><code>name: sklearn_logistic_regression\nmodels:\n- name: logreg\ntraining:\ntask:\ntaskRef: training\ntasks:\n- name: training\n!poetry\nexecutor:\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p><code>training.task</code> can contain a complete task, we simply use the taskRef field to keep our file readable. We could have placed an  entire task inside the model configuration directly.  </p> <p>Now we can run <code>ame model train logreg --logs</code> and perform a training. Under the hood this does essentially the same thing as  just running the task directly.</p> <p>Now lets look at deploying our model.</p> <pre><code>name: sklearn_logistic_regression\nmodels:\n- name: logreg\ntraining:\ntask:\ntaskRef: training\ndeployment:\nautoDeploy: true\ntasks:\n- name: training\n!poetry\nexecutor:\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>Setting auto deployment to true will tell AME to always deploy latest version of a model. Deployment in this context means spinning up an inference server. As AME needs some persitent context when managing a model deployment we have to synchronize our project to  the AME instance. This could be done via a Git repo and for production use cases that is highly recommended. For experimention and  educational purposes we can manually place our local version of the project in the cluster. Run <code>ame project sync</code> and AME will automatically train a version of the model, if needed and deploy an inference server for the model.</p>"},{"location":"user_guide/model_validation/#validating-models-before-deployment","title":"Validating models before deployment","text":"<p>To ensure that a new model versions perform well before exposing them AME supports model validation. This is done by providing AME with a <code>Task</code> which  will succeed if the model passes validation and fail if not.</p> <p>Example from ame-demo:</p> <pre><code>projectid: sklearn_logistic_regression\nmodels:\n- name: logreg\ntype: mlflow\nvalidationTask: # the validation task is set here.\ntaskRef: mlflow_validation training: task:\ntaskRef: training\ndeployment:\nauto_train: true\ndeploy: true\nenable_tls: false\ntasks:\n- name: training\nprojectid: sklearn_logistic_regression\ntemplateRef: shared-templates.logistic_reg_template\ntaskType: Mlflow\n- name: mlflow_validation\nprojectid: sklearn_logistic_regression\nruncommand: python validate.py\n</code></pre> <p>This approach allows for a lot of flexibility of how models are validated, at the cost of writing the validation your self. In the future AME will provide builtin options for common validation configurations as well, see the roadmap.</p>"},{"location":"user_guide/model_validation/#using-mlflow-metrics","title":"Using MLflow metrics","text":"<p>Here we will walk through how to validate a model based on recorded metrics in MLflow, using the ame-demo repository as an example. The model is a simple logistic regresser, the training code looks like this:</p> <pre><code>import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nimport mlflow\nimport mlflow.sklearn\nimport os\nif __name__ == \"__main__\":\nX = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\ny = np.array([0, 0, 1, 1, 1, 0])\nlr = LogisticRegression()\nlr.fit(X, y)\nscore = lr.score(X, y)\nprint(\"Score: %s\" % score)\nmlflow.log_metric(\"score\", score)\nmlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"logreg\")\nprint(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n</code></pre> <p>Notice how the score is logged as a metric. We can use that in our validation.</p> <p>AME exposes the necessary environment variables to running tasks so we can access the Mlflow instance during validation just by using the Mlflow library.</p> <pre><code>TODO\n</code></pre>"},{"location":"user_guide/models/","title":"Models","text":"<p>Models are one of AME's higher level constructs, see what that means here. if you are configuring how a model should be trained, deployed, monitored or validated this is the right place. Models exist in an AME file along side Datasets Tasks and Templates.</p>"},{"location":"user_guide/models/#model-training","title":"Model training","text":"<p>Model training is configured described use a Task.</p> <p>AME can be deployed with a an MLflow instance which will be exposed to the Training Task allowing for simple storage and retrievel of models metrics and experiments.</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask: taskRef: train_my_model tasks:\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/models/#model-deployment","title":"Model deployment","text":"<p>If AME is setup with a model reigstry see supported registries here models can be deployed for inference.</p> <p>Just like for <code>Tasks</code>, you can and probably should define the resources required to perform inference with your model. Here are configuration examples with the serving options available with AME.</p>"},{"location":"user_guide/models/#mlflow","title":"Mlflow","text":"<pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask: taskRef: train_my_model deployment:\nresources:\nmemory: 10G\ncpu: 4\nstorage: 10G\nnvidia.com/gpu: 1\nautoDeploy: true\ntasks:\n...\n</code></pre>"},{"location":"user_guide/models/#mlserver","title":"MLserver","text":"<p>Mlserver support is planned for a future release, see issue</p>"},{"location":"user_guide/models/#kserve","title":"Kserve","text":"<p>Mlserver support is planned for a future release, see issue</p>"},{"location":"user_guide/models/#triton","title":"Triton","text":""},{"location":"user_guide/models/#advanced-deployment-configuration","title":"Advanced deployment configuration","text":""},{"location":"user_guide/models/#ingress","title":"Ingress","text":"<p>If you are hosting AME your self, there are a number of decisions that need to be made with regards to mode deployment. Currently AME does not automatically generate an ingress configuration and therefore one must be provided either. You can provide a cluster wide default as well as individual override for models.</p> <p>See how to set a cluster wide default here.</p> <p>Model specific ingress can be set here. The plan is to provide better abstractions to avoid having to work with this directly, see this.</p> <p>Setting model deployment ingress:</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ndeployment:\ningressAnnotations:\nTODO\nresources:\nmemory: 10G\ncpu: 4\nstorage: 10G\nnvidia.com/gpu: 1\nautoDeploy: true\ntasks:\n...\n</code></pre>"},{"location":"user_guide/models/#replicas","title":"Replicas","text":"<p>For productioon deploiyments you will likely want some degree of relication for model instances. Custer wide defaults can be set here. Model specific replicas can set like this:</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ndeployment:\nreplicas: 3\n...\ntasks:\n...\n</code></pre>"},{"location":"user_guide/models/#image","title":"Image","text":"<p>If AME's default deployment image is insufficient for your use case a custom image can be set. This can be change cluster wide here.</p> <p>Model specific deployment images can be set like this:</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ndeployment:\nimage: my.deployment.image\n...\ntasks:\n...\n</code></pre> <p>If a secret is required to access the image remember to provide that secret to AME, a guide is here.</p>"},{"location":"user_guide/models/#model-validation","title":"Model validation","text":"<p>AME supports validating models versions before they are deployed. To enable this we have to provide a task that will succeed or fail based on the validity of a model version. See a guide here.</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\nvalidation:\ntask:\ntaskRef: model_validation\ntasks:\n...\n</code></pre>"},{"location":"user_guide/models/#model-monitoring","title":"Model monitoring","text":""},{"location":"user_guide/models/#batch-inference","title":"Batch inference","text":"<p>TODO add a reference with all objects and options.</p>"},{"location":"user_guide/project_sources/","title":"Project sources","text":"<p>A project source informs AME of a location to check and sync an AME project from. Currently the only supported location is a Git repository.</p>"},{"location":"user_guide/project_sources/#git-project-sources","title":"Git project sources","text":"<p>Git project sources allow for a Gitops like approach to managing models, data and the surrounding operations using the AME file defined in the repository.</p>"},{"location":"user_guide/project_sources/#how-to-use-git-project-sources","title":"How to use Git project sources","text":"<p>You can create a Git project source either through the CLI or the AME frontend.</p> <p>Below are a few examples with the CLI</p> <pre><code># A public repository:\name projectsrc create https://github.com/TeaInSpace/ame-demo.git\n\n# A private repository:\name projectsrc create https://github.com/TeaInSpace/ame-demo.git --secret MY_SECRET_ID\n\n# Edit the secret for an existing project source:\name projectsrc edit https://github.com/TeaInSpace/ame-demo.git --secret MY_SECRET_ID\n</code></pre> <p>AME will attempt to warn you of issues as early as possible. For example if AME fails to clone the the repository the CLI will make that clear.</p> <p>Example:</p> <p>TODO: insert image</p> <p>Once AME has a valid project source it will check all branches for AME files and track them according to the tracking configuration specified in each file.</p>"},{"location":"user_guide/tasks/","title":"Tasks","text":"<p><code>Tasks</code> are the basic building block for most of AME's functionality. A <code>Task</code> represents some work to be done, often in the form of python code to be executed but in principle it can be anything executable in a container.</p> <p><code>Tasks</code> are configured in an AME file <code>ame.yml</code>. </p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre> <p>This is an example of a the absolute minimal requirements for a task, a name and an executor. An executor specifies how a task should be executed, a complete list can found (here)[]. In this case AME will ensure that the specified python version is present and use poetry to install dependencies and enter a shell before executing the command <code>python train.py</code>. </p> <p>To run the task manually simply enter the directory with the file and project and run <code>ame task run -l train_my_model</code>. The <code>-l</code> ensures that we are using the local context and not trying to run a remote task already present in the AME cluster. Alternatively if you don't want to type the name omit it and AME will present a list of the available <code>Tasks</code>.</p> <p>This page provides an overview of working with Task's using the cli and dashboard as well as reference of all configuration options. </p>"},{"location":"user_guide/tasks/#working-with-tasks","title":"Working with Tasks","text":""},{"location":"user_guide/tasks/#cli-commands","title":"Cli commands","text":"<p>The AME cli contains a subcommand <code>ame task</code> which is for operating on Tasks.</p>"},{"location":"user_guide/tasks/#view-deployed-tasks","title":"View deployed Tasks","text":"<pre><code>ame task list\n\nName                                                        Status    Project ameprojectsrc56k2rlogregtrainingsklearn-logistic-regression Succeeded Unknown ameprojectsrcj8264logregtrainingdatasetdemo                 Failed    Unknown datasetdatasetdemodataset1dataset1-fetcher                  Succeeded Unknown validate-logreg-1                                           Succeeded Unknown </code></pre>"},{"location":"user_guide/tasks/#run-a-task","title":"Run a task","text":"<p>Individual task's can be run with <code>ame task run</code>. This will look for Tasks in your current project. Upload any files necessary and execute the task. </p>"},{"location":"user_guide/tasks/#view-task-logs","title":"View task logs","text":"<p>Task logs for any running task can be viewed with <code>ame task logs</code>.</p>"},{"location":"user_guide/tasks/#task-reference","title":"Task Reference","text":"<p>Reference for all configuration for AME Tasks.</p>"},{"location":"user_guide/tasks/#resource-requirements","title":"Resource requirements","text":"<p>By default a task gets limited resources allocated TODO: what is the default? which can be fine for very simple tasks but anything non trivial will require. To change the default see how to configure default (here)[].</p> <p>Resources include any computational resources that needs to be allocated:</p> <ul> <li>CPU</li> <li>GPU</li> <li>memory</li> <li>storage</li> </ul> <p>They can be specified for a task with the resources field:</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\n</code></pre> <p>AME uses style of string units for resources as Kubernetes. If you are not familiar with that no worries!, the readon for the details.</p> <p>Memory and storage units: memory units are measured in bytes. Integers with quantity suffixes can be used to express memory quantities.  See the following table for complete list of available units. </p> Unit Suffix Example Exabyte E 2.5E Exbibyte Ei 2.5Ei Terabyte T 2.5T Tebibyte Ti 2.5Ti Gigabyte G 2.5G Gibibyte Gi 2.5Gi Megabyte M 2.5M Mebibyte Mi 2.5Mi Kilobyte k 2.5k Kibibyte Ki 2.5Ki Byte 2.5 Fraction of a Byte m 2500m <p>TODO: make better example Example: <pre><code>  128974848, 129e6, 129M,  128974848000m, 123Mi\n</code></pre></p> <p>CPU units</p> <p><code>1</code> specifies a single CPU thread either virtual or hyperthreaded depending on the underlying machine. <code>0.5</code> specifies half a CPU thread and so does <code>500m</code>. <code>1=1000m</code>, <code>m</code> stands for millicpu/millicores.</p> <p>GPU units</p> <p>GPU scheduling in AME is current pretty barebones. You must specifie whole GPUs, meaning no fractional units and you can't ask for a specific model of device only vendor. For cases where different GPU models need to be differentiate node labels can be used as a work around. This is essentially the way Kubernetes solves GPU scheduling as well, however we will be abstracting all this away in the coming release of AME to allow for requesting specific models and fractional GPU sharing directly in the Task specification, see the tracking (issue)[]. For details on how to use node labels with GPUs see (this)[].</p>"},{"location":"user_guide/tasks/#secrets","title":"Secrets","text":"<p>Task's will often require access to private resources such as objectstorage, databases or APIs. AME provides a built in secret store as well as integration with (Vault)[https://www.vaultproject.io/]. This section will walk through how to use secrets with a Task. For details on AME's secret store and how to integrate with a Vault instance see the relevant (documentation)[].</p> <p>Quick example</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\nsecrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre> <p>Explanation</p> <p><code>!ame</code> and <code>!vault</code> indicate the type of secret being specified. <code>key</code> is the key that identifies the secret for both variants. <code>injectAs</code> specifies the name of the environment variable. <code>vault</code> specifies the name of the vault to use.</p> <p>A secret can be out in AME's secret store using the secret sub command: <code>ame secret add</code>. The will prompts will ask for a key and value.</p>"},{"location":"user_guide/tasks/#container-images","title":"Container images","text":"<p>The default image is intended to cover most cases. It uses the latest LTS version of Ubuntu with a non slim environment. Most projects should just work inside this environment. How ever there a few reasons you might want to replace the default image with your own. </p> <p>Special library requiremetents: if a package you are using requires some system library that is not installed by default you can address this by creating a custom image. In this  case it probably makes sense to take the base AME image and extend it with the dependencies you need. If you think this dependency should be included in the base image feel free to create and issue on Github.</p> <p>Security: depending on your needs a full blown Ubuntu environment might have too many security issues due to all of the packages installed by default. In this case creating a minimal image with the exact requirements you is the way to go. See guide on doing that here.</p> <p>TODO: how do we ignore large files?</p>"},{"location":"user_guide/tasks/#task-cleanup","title":"Task cleanup","text":""},{"location":"user_guide/tasks/#executors","title":"Executors","text":"<p>An executor describes how AME should execute a task. It does this by providing enough information for AME to know how dependencies should be installed and how a Task is run. </p> <p>All executes support overriding the default image with the image field. Read more about the default image used by AME and overriding it with your own here.</p> <p>TODO: How to change versions of dependency managers???</p>"},{"location":"user_guide/tasks/#quick-examples","title":"Quick examples","text":""},{"location":"user_guide/tasks/#poetry-executor","title":"Poetry executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#pip-executor","title":"Pip executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#pipenv-executor","title":"Pipenv executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!pipenv\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#mlflow-executor","title":"MLflow executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!mlflow\npythonVersion: 3.11\ncommand: python train.py # TODO should the command be specified here??\n</code></pre>"},{"location":"user_guide/tasks/#custom-executor","title":"Custom executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!custom\npythonVersion: 3.11\ncommand: python train.py # TODO should the command be specified here??\n</code></pre>"},{"location":"user_guide/tasks/#poetry-executor_1","title":"Poetry executor","text":"<p>The Poetry executor expects a Poetry compatible project. This means a pyproject.taml and poetry.lock file should be present.  Note that the python version is required to be specified, in the future this information will be extracted from pyproject.toml. The value  in the command field is executed using poetry run and it used to start the task.</p> <pre><code>    executor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#pipenv-executor_1","title":"Pipenv executor","text":"<p>The Pipenv executor expects a Pipenv compatible project. This means a Pipfile and Pipfile.lock file should be present.  The python version is installed by pipenv following the value in the Pipfile. The value  in the command field is executed inside a shell created with pipenv shell.</p> <pre><code>    executor:\n!pipenv\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#pip-executor_1","title":"Pip executor","text":"<p>The expects a project where pip can install dependencies. This means a requirements.txt file should be present. We strongly recommend that versions are specified in the requirements.txt file to ensure that the project will run just like on your local machine. The value  in the command field is executed inside a virtual environment created used venv with the dependencies installed by pip.</p> <pre><code>    executor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"user_guide/tasks/#custom-executor_1","title":"Custom executor","text":"<p>The custom executor is meant for special cases where the other executors are insufficient. For example if you are not using python. No setup is performed in this case, the command is simply executed inside a container.</p> <pre><code>    executor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\nimage: myimage\n</code></pre>"},{"location":"user_guide/tasks/#common-task-examples","title":"Common task examples","text":""},{"location":"user_guide/tasks/#templates","title":"Templates","text":"<p>If you find yourself repeating a lot of Task configuration it might be useful to create templates for common configuration. Templates are partial Tasks that can be used as the base for a Task, any fields set in the Task will then override the Template. The combination of Task and Template fields must yield a valid Task.</p>"},{"location":"user_guide/tasks/#quick-examples_1","title":"Quick examples","text":""},{"location":"user_guide/tasks/#template-and-task-in-the-same-project","title":"Template and Task in the same project","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nfromTemplate: name: xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\ntemplates:\n- name: xgboost_resources # Note that this is the name of the template\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 secrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre>"},{"location":"user_guide/tasks/#template-imported-from-a-separate-project","title":"Template imported from a separate project","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: train_my_model\nfromTemplate: name: xgboost_resources\nproject: shared_templates\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n# other project ame.yml\nproject: shared_templates\ntemplates:\n- name: xgboost_resources # Note that this is the name of the template\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 secrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre>"},{"location":"user_guide/tasks/#example-notes","title":"Example notes","text":"<p>See the (section)[] on importing from other projects for more details.</p>"},{"location":"user_guide/tasks/#importing-from-other-projects","title":"Importing from other projects","text":""},{"location":"user_guide/tasks/#task-input-and-output-data-artifacts-and-saving","title":"Task input and output data (artifacts and saving)","text":"<p>Tasks can load data using Datasets and save artifacts to the object storage AME is configured too use.</p>"},{"location":"user_guide/tasks/#quick-examples_2","title":"Quick examples","text":""},{"location":"user_guide/tasks/#save-data-in-paths-to-object-storage","title":"Save data in paths to object storage","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\nartifacts:\npaths:\n- path/to/artifact_dir\n</code></pre>"},{"location":"user_guide/tasks/#automatically-store-new-or-changed-files-as-artifacts","title":"Automatically store new or changed files as artifacts","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\nartifacts:\nsaveChangedFiles: true\n</code></pre>"},{"location":"user_guide/tasks/#load-data-from-a-dataset","title":"Load data from a dataset","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\ndataSets:\n- ref:\nname: somedataset\nproject: anotherproject\nartifacts:\nsaveChangedFiles: true\n</code></pre>"},{"location":"user_guide/tasks/#task-reference_1","title":"Task reference","text":"<p>Tasks can reference other Tasks. This is intended for usecases where inlining a Task is cumbersome for example when adding a model training Task or a Task pipeline. </p>"},{"location":"user_guide/tasks/#quick-examples_3","title":"Quick examples","text":""},{"location":"user_guide/tasks/#referencing-a-task-for-model-training","title":"Referencing a Task for model training","text":"<pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask: # Remember this field expects a Task\ntaskRef: train_my_model # This is considered a complete Task\ntasks:\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>Alternatively if we were to inline the Task it would look like:</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask:\nname: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/tasks/#referencing-a-task-from-a-task","title":"Referencing a Task from a Task","text":"<pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask:\ntaskRef: train_my_model tasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>Currently it is not supported to reference a Task from a different project but that is likely to be implemented in some form in the near future </p>"},{"location":"user_guide/tasks/#triggering-tasks","title":"Triggering Tasks","text":"<p>For some usecases it might be required to automatically kick off a Task. If you are working with a high level construct such as a dataset or Model we recommended that you first check if it has a mechanism that suits your needs as AME can often help you do less work that way. For example a Model automatically keep deployment up to date and trigger validation before  deployming any new versions. Doing this manually would be non trivial. If you have a need not already covered read on.</p> <p>The main mechanism of triggering independent Tasks is time based. We will be implementing more triggers for example git based triggers in the coming release.</p> <p>In order to have a Task triggered on some recurring basis two things are required. A project with that Task must be present in an AME cluster and the desired Task must have the trigger field configured.</p>"},{"location":"user_guide/tasks/#quick-examples_4","title":"Quick examples","text":""},{"location":"user_guide/tasks/#trigger-task-with-cron-schedule","title":"Trigger Task with cron schedule","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: my_task\ntaskRef: train_my_model\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\ntriggers:\nschedule: ***** # TODO some cron schedule\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/tasks/#dags","title":"DAGS","text":""},{"location":"user_guide/tasks/#working-with-tasks_1","title":"Working with Tasks","text":""},{"location":"user_guide/tasks/#pipelines","title":"Pipelines","text":"<p>A task can consist of sub tasks.</p>"},{"location":"user_guide/tasks/#quick-examples_5","title":"Quick examples","text":""},{"location":"user_guide/tasks/#pipeline-with-inline-sequential-tasks","title":"Pipeline with inline sequential tasks","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- name: preprocessing executor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/tasks/#pipeline-with-equential-tasks-referenced","title":"Pipeline with equential tasks referenced","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- taskref: preprocessing\n- taskref: training\n- name: preprocessing\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/tasks/#pipeline-with-parallel-tasks","title":"Pipeline with parallel tasks","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- - taskref: prepare_dataset_one - taskref: prepare_datast_two - taskref: training\n- name: prepare_dataset_one\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data_one.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: prepare_dataset_two\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data_two.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"user_guide/tasks/#environment-variables","title":"Environment variables","text":"<p>Environment variable can be set with the <code>environment</code> field. The field accepts a list of key value pairs, see the example below.</p> <p>Note that there are a few environment variables set by AME, future releases of AME will return an error if you attempt to override them, see this (issue)[]. </p> <pre><code># Provided environment variables\n# TODO fill this out\nMLFLOW...\n</code></pre> <p>Quick example</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\nenvironment:\n# inject environment variable SOME_VAR=SOME_VAL\n- key: SOME_VAR\nval: SOME_VAL\n</code></pre>"},{"location":"user_guide/tasks/#escape-hatches","title":"Escape hatches","text":"<p>TODO</p>"},{"location":"user_guide/tasks/#techinical-details-of-tasks","title":"Techinical details of Tasks","text":""}]}