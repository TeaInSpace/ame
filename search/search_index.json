{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"datasets/","title":"Data Sets","text":"<p>AME has a builtin notion of data sets in allowing user's to think in terms of data sets and not just raw tasks. </p> <p>Here is an example of what a simple data set configuration looks like:</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\n#    task:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre> <p>In the simplest form a data set is just a task which produces data a long with a storage mechanism. This allows for a number of benefits over just using tasks directly. Data can be produced once and used many times, for example if a number of tasks are scheduled AME can prepare the dataset once and use it across all of the dependent tasks.</p>"},{"location":"datasets/#configuring-a-data-set","title":"Configuring a data set","text":"<p>A simple data set cfg is quick to set and can then be progressively enhanced as your needs expand. Here we will walk through the process of first setting up a simple data set and then go through the more advanced options.</p> <p>The minimum requirements for a dataset is a <code>path</code> pointer to where data should be saved from and a <code>Task</code> which will produce data at that path. As shown in the mnist example above. Lets start with that here:</p> <pre><code># ame.yaml\n...\ndataSets:\n- name: mnist\npath: ./data # Specifies where the tasks stores data.\n#    task:\ntaskRef: fetch_mnist # References a task which produces data.     \n</code></pre> <p>So far so good, we have a path <code>data</code> and reference a <code>Task</code> that produces our data.</p>"},{"location":"datasets/#interacting-with-data-sets","title":"Interacting with data sets","text":"<p>To see the status of live data sets, use the AME's cli. Current it is only possible to see data sets that are in use, meaning referenced by some running task.</p> <pre><code>ame ds list\n</code></pre>"},{"location":"model_validation/","title":"Guides","text":""},{"location":"model_validation/#from-zero-to-live-model","title":"From zero to live model","text":"<p>This guide is focused on using AME if you are looking for a deployment guide go here.</p> <p>This guide will walk through going from zero to having a model served through an the V2 inference protocol. it will be split into multiple sub steps which can be consumed in isolation if you are just looking for a smaller guide on that specific step.</p> <p>Almost any python project should be usable but if you want to follow along with the exact same project as the guide clone this repo.</p>"},{"location":"model_validation/#setup-the-cli","title":"Setup the CLI","text":"<p>Before we can initialise an AME project we need to install the ame CLI and connect with your AME instance.</p> <p>TODO describe installation</p>"},{"location":"model_validation/#initialising-ame-in-your-project","title":"Initialising AME in your project","text":"<p>The first step will be creating an <code>ame.yaml</code> file in the project directory.</p> <p>This is easiet to do with the ame CLI by running <code>ame project init</code>. The CLI will ask for a project and then produce a file that looks like this:</p> <pre><code>projectName: sklearn_logistic_regression\n</code></pre>"},{"location":"model_validation/#the-first-training","title":"The first training","text":"<p>Not very exciting but it is a start. Next we want to set up our model to be run by AME. The most important thing here is the Task that will train the model so lets start with that.</p> <p>Here we need to consider a few things, what command is used to train a model, how are dependencies managed in our project, what python version do we need and how many resources does our model training require.</p> <p>If you are using the repo for this guide, you will want a task configured as below. </p> <pre><code>projectid: sklearn_logistic_regression\ntasks:\n- name: training\n!poetry\nexecutor:\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"model_validation/#your-first-task","title":"Your first Task","text":"<p><code>Tasks</code> are an important building block for AME. This guide will walk you through the basic of constructing and running <code>Task</code>. </p> <p>We assume that the AME CLI is setup and connected to an AME instance. If not see this guide. </p> <p>Before we can run a task we must have a project setup. To init a project follow the commands as shown below, replacing myproject with the  path to your project.</p> <pre><code>cd myproject\name init\n</code></pre> <p>Now you should have an AME file ame.yaml inside your project: <pre><code>name: myproject\n</code></pre></p> <p>Not very exciting yet. Next we want to add a Task to this file so we can run it. Update your file to match the changes shown below.</p> <pre><code>name: myproject\ntasks:\n- name: training\n!poetry\nexecutor:\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 2G cpu: 2 storage: 10G </code></pre> <p>Here we add a list of tasks for our project, containing a single <code>Task</code> called training. Lets look at the anatomy of training.</p> <p>First we set the name <code>name: training</code>, pretty standard YAML. Next we set the executor. This syntax might seem a bit confusing if you have not used this YAML feature before. <code>!poetry</code> adds a tag to the executor indicating the executor type. In this case we are  using the poetry executor. It requires two fields to be set. the Python version and the command to run. This tells AME how to execute the <code>Task</code>.</p> <p>Finally we set the required resources. 2G ram, 2 cpu threads and 10G of storage.</p> <p>To run the task we can use the CLI: <pre><code>ame task run\n</code></pre></p>"},{"location":"model_validation/#validating-models-before-deployment","title":"Validating models before deployment","text":"<p>To ensure that a new model versions perform well before exposing them AME supports model validation. This is done by providing AME with a <code>Task</code> which  will succeed if the model passes validation and fail if not.</p> <p>Example from ame-demo:</p> <pre><code>projectid: sklearn_logistic_regression\nmodels:\n- name: logreg\ntype: mlflow\nvalidationTask: # the validation task is set here.\ntaskRef: mlflow_validation training: task:\ntaskRef: training\ndeployment:\nauto_train: true\ndeploy: true\nenable_tls: false\ntasks:\n- name: training\nprojectid: sklearn_logistic_regression\ntemplateRef: shared-templates.logistic_reg_template\ntaskType: Mlflow\n- name: mlflow_validation\nprojectid: sklearn_logistic_regression\nruncommand: python validate.py\n</code></pre> <p>This approach allows for a lot of flexibility of how models are validated, at the cost of writing the validation your self. In the future AME will provide builtin options for common validation configurations as well, see the roadmap.</p>"},{"location":"model_validation/#using-mlflow-metrics","title":"Using MLflow metrics","text":"<p>Here we will walk through how to validate a model based on recorded metrics in MLflow, using the ame-demo repository as an example. The model is a simple logistic regresser, the training code looks like this:</p> <pre><code>import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nimport mlflow\nimport mlflow.sklearn\nimport os\nif __name__ == \"__main__\":\nX = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\ny = np.array([0, 0, 1, 1, 1, 0])\nlr = LogisticRegression()\nlr.fit(X, y)\nscore = lr.score(X, y)\nprint(\"Score: %s\" % score)\nmlflow.log_metric(\"score\", score)\nmlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"logreg\")\nprint(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n</code></pre> <p>Notice how the score is logged as a metric. We can use that in our validation.</p> <p>AME exposes the necessary environment variables to running tasks so we can access the Mlflow instance during validation just by using the Mlflow library.</p> <pre><code>TODO\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>Models are one of AME's higher level constructs, see what that means here. if you are configuring how a model should be trained, deployed, monitored or validated this is the right place. Models exist in an AME file along side Datasets Tasks and Templates.</p>"},{"location":"models/#model-training","title":"Model training","text":"<p>Model training is configured described use a Task.</p> <p>AME can be deployed with a an MLflow instance which will be exposed to the Training Task allowing for simply storage and retrievel of models and metrics.</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask: taskRef: train_my_model tasks:\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"models/#model-deployment","title":"Model deployment","text":""},{"location":"models/#model-validation","title":"Model validation","text":""},{"location":"models/#model-monitoring","title":"Model monitoring","text":""},{"location":"models/#batch-inference","title":"Batch inference","text":""},{"location":"project_sources/","title":"Project sources","text":"<p>A project source informs AME of a location to check and sync an AME project from. Currently the only supported location is a Git repository.</p>"},{"location":"project_sources/#git-project-sources","title":"Git project sources","text":"<p>Git project sources allow for a Gitops like approach to managing models, data and the surrounding operations using the AME file defined in the repository.</p>"},{"location":"project_sources/#how-to-use-git-project-sources","title":"How to use Git project sources","text":"<p>You can create a Git project source either through the CLI or the AME frontend.</p> <p>Below are a few examples with the CLI</p> <pre><code># A public repository:\name projectsrc create https://github.com/TeaInSpace/ame-demo.git\n\n# A private repository:\name projectsrc create https://github.com/TeaInSpace/ame-demo.git --secret MY_SECRET_ID\n\n# Edit the secret for an existing project source:\name projectsrc edit https://github.com/TeaInSpace/ame-demo.git --secret MY_SECRET_ID\n</code></pre> <p>AME will attempt to warn you of issues as early as possible. For example if AME fails to clone the the repository the CLI will make that clear.</p> <p>Example:</p> <p>TODO: insert image</p> <p>Once AME has a valid project source it will check all branches for AME files and track them according to the tracking configuration specified in each file.</p>"},{"location":"tasks/","title":"Tasks","text":"<p><code>Tasks</code> are the basic building block for most of AME's functionality. A <code>Task</code> represents some work to be done, often in the form of python code to be executed but in principle it can be anything executable in a container.</p> <p><code>Tasks</code> are configured in an AME file <code>ame.yml</code>. </p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre> <p>This is an example of a the absolute minimal requirements for a task, a name and an executor. An executor specifies how a task should be executed, a complete list can found (here)[]. In this case AME will ensure that the specified python version is present and use poetry to install dependencies and enter a shell before executing the command <code>python train.py</code>. </p> <p>To run the task manually simply enter the directory with the file and project and run <code>ame task run -l train_my_model</code>. The <code>-l</code> ensures that we are using the local context and not trying to run a remote task already present in the AME cluster. Alternatively if you don't want to type the name omit it and AME will present a list of the available <code>Tasks</code>.</p>"},{"location":"tasks/#resource-requirements","title":"Resource requirements","text":"<p>By default a task gets limited resources allocated TODO: what is the default? which can be fine for very simple tasks but anything non trivial will require. To change the default see how to configure default (here)[].</p> <p>Resources include any computational resources that needs to be allocated:</p> <ul> <li>CPU</li> <li>GPU</li> <li>memory</li> <li>storage</li> </ul> <p>They can be specified for a task with the resources field:</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\n</code></pre> <p>AME uses style of string units for resources as Kubernetes. If you are not familiar with that no worries!, the readon for the details.</p> <p>Memory and storage units: memory units are measured in bytes. Integers with quantity suffixes can be used to express memory quantities.  See the following table for complete list of available units. </p> Unit Suffix Example Exabyte E 2.5E Exbibyte Ei 2.5Ei Terabyte T 2.5T Tebibyte Ti 2.5Ti Gigabyte G 2.5G Gibibyte Gi 2.5Gi Megabyte M 2.5M Mebibyte Mi 2.5Mi Kilobyte k 2.5k Kibibyte Ki 2.5Ki Byte 2.5 Fraction of a Byte m 2500m <p>TODO: make better example Example: <pre><code>  128974848, 129e6, 129M,  128974848000m, 123Mi\n</code></pre></p> <p>CPU units</p> <p><code>1</code> specifies a single CPU thread either virtual or hyperthreaded depending on the underlying machine. <code>0.5</code> specifies half a CPU thread and so does <code>500m</code>. <code>1=1000m</code>, <code>m</code> stands for millicpu/millicores.</p> <p>GPU units</p> <p>GPU scheduling in AME is current pretty barebones. You must specifie whole GPUs, meaning no fractional units and you can't ask for a specific model of device only vendor. For cases where different GPU models need to be differentiate node labels can be used as a work around. This is essentially the way Kubernetes solves GPU scheduling as well, however we will be abstracting all this away in the coming release of AME to allow for requesting specific models and fractional GPU sharing directly in the Task specification, see the tracking (issue)[]. For details on how to use node labels with GPUs see (this)[].</p>"},{"location":"tasks/#secrets","title":"Secrets","text":"<p>Task's will often require access to private resources such as objectstorage, databases or APIs. AME provides a built in secret store as well as integration with (Vault)[https://www.vaultproject.io/]. This section will walk through how to use secrets with a Task. For details on AME's secret store and how to integrate with a Vault instance see the relevant (documentation)[].</p> <p>Quick example</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\nsecrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre> <p>Explanation</p> <p><code>!ame</code> and <code>!vault</code> indicate the type of secret being specified. <code>key</code> is the key that identifies the secret for both variants. <code>injectAs</code> specifies the name of the environment variable. <code>vault</code> specifies the name of the vault to use.</p> <p>A secret can be out in AME's secret store using the secret sub command: <code>ame secret add</code>. The will prompts will ask for a key and value.</p>"},{"location":"tasks/#container-images","title":"Container images","text":"<p>The default image is intended to cover most cases. It uses the latest LTS version of Ubuntu with a non slim environment. Most projects should just work inside this environment. How ever there a few reasons you might want to replace the default image with your own. </p> <p>Special library requiremetents: if a package you are using requires some system library that is not installed by default you can address this by creating a custom image. In this  case it probably makes sense to take the base AME image and extend it with the dependencies you need. If you think this dependency should be included in the base image feel free to create and issue on Github.</p> <p>Security: depending on your needs a full blown Ubuntu environment might have too many security issues due to all of the packages installed by default. In this case creating a minimal image with the exact requirements you is the way to go. See guide on doing that here.</p> <p>TODO: how do we ignore large files?</p>"},{"location":"tasks/#task-cleanup","title":"Task cleanup","text":""},{"location":"tasks/#executors","title":"Executors","text":"<p>An executor describes how AME should execute a task. It does this by providing enough information for AME to know how dependencies should be installed and how a Task is run. </p> <p>All executes support overriding the default image with the image field. Read more about the default image used by AME and overriding it with your own here.</p> <p>TODO: How to change versions of dependency managers???</p>"},{"location":"tasks/#quick-examples","title":"Quick examples","text":""},{"location":"tasks/#poetry-executor","title":"Poetry executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#pip-executor","title":"Pip executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#pipenv-executor","title":"Pipenv executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!pipenv\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#mlflow-executor","title":"MLflow executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!mlflow\npythonVersion: 3.11\ncommand: python train.py # TODO should the command be specified here??\n</code></pre>"},{"location":"tasks/#custom-executor","title":"Custom executor","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!custom\npythonVersion: 3.11\ncommand: python train.py # TODO should the command be specified here??\n</code></pre>"},{"location":"tasks/#poetry-executor_1","title":"Poetry executor","text":"<p>The Poetry executor expects a Poetry compatible project. This means a pyproject.taml and poetry.lock file should be present.  Note that the python version is required to be specified, in the future this information will be extracted from pyproject.toml. The value  in the command field is executed using poetry run and it used to start the task.</p> <pre><code>    executor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#pipenv-executor_1","title":"Pipenv executor","text":"<p>The Pipenv executor expects a Pipenv compatible project. This means a Pipfile and Pipfile.lock file should be present.  The python version is installed by pipenv following the value in the Pipfile. The value  in the command field is executed inside a shell created with pipenv shell.</p> <pre><code>    executor:\n!pipenv\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#pip-executor_1","title":"Pip executor","text":"<p>The expects a project where pip can install dependencies. This means a requirements.txt file should be present. We strongly recommend that versions are specified in the requirements.txt file to ensure that the project will run just like on your local machine. The value  in the command field is executed inside a virtual environment created used venv with the dependencies installed by pip.</p> <pre><code>    executor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\n</code></pre>"},{"location":"tasks/#custom-executor_1","title":"Custom executor","text":"<p>The custom executor is meant for special cases where the other executors are insufficient. For example if you are not using python. No setup is performed in this case, the command is simply executed inside a container.</p> <pre><code>    executor:\n!pip\npythonVersion: 3.11\ncommand: python train.py\nimage: myimage\n</code></pre>"},{"location":"tasks/#common-task-examples","title":"Common task examples","text":""},{"location":"tasks/#templates","title":"Templates","text":"<p>If you find yourself repeating a lot of Task configuration it might be useful to create templates for common configuration. Templates are partial Tasks that can be used as the base for a Task, any fields set in the Task will then override the Template. The combination of Task and Template fields must yield a valid Task.</p>"},{"location":"tasks/#quick-examples_1","title":"Quick examples","text":""},{"location":"tasks/#template-and-task-in-the-same-project","title":"Template and Task in the same project","text":"<pre><code># ame.yml\ntasks:\n- name: train_my_model\nfromTemplate: name: xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\ntemplates:\n- name: xgboost_resources # Note that this is the name of the template\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 secrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre>"},{"location":"tasks/#template-imported-from-a-separate-project","title":"Template imported from a separate project","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: train_my_model\nfromTemplate: name: xgboost_resources\nproject: shared_templates\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\n# other project ame.yml\nproject: shared_templates\ntemplates:\n- name: xgboost_resources # Note that this is the name of the template\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 secrets:\n- !ame # Secret stored by AME\nkey: blob_storage_key # Key identifying a secret in AME's secret store.\ninjectAs: MY_BLOB_STORAGE_SECRET # This will inject an environment variable with the name MY_BLOB_STORAGE_SECRET and with the value of the secret.\n# TODO this does not cover all vault cases\n- !vault # Secret stored in Vault\nvault: company_vault # Name of the vault to use.\nkey: path/to/secret # Path to the secret in Vault.\ninjectAs: COMPANY_SECRET  # This will inject an environment variable with the name COMPANY_SECRET and with the value of the secret.\n</code></pre>"},{"location":"tasks/#example-notes","title":"Example notes","text":"<p>See the (section)[] on importing from other projects for more details.</p>"},{"location":"tasks/#importing-from-other-projects","title":"Importing from other projects","text":""},{"location":"tasks/#task-input-and-output-data-artifacts-and-saving","title":"Task input and output data (artifacts and saving)","text":"<p>Tasks can load data using Datasets and save artifacts to the object storage AME is configured too use.</p>"},{"location":"tasks/#quick-examples_2","title":"Quick examples","text":""},{"location":"tasks/#save-data-in-paths-to-object-storage","title":"Save data in paths to object storage","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\nartifacts:\npaths:\n- path/to/artifact_dir\n</code></pre>"},{"location":"tasks/#automatically-store-new-or-changed-files-as-artifacts","title":"Automatically store new or changed files as artifacts","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\nartifacts:\nsaveChangedFiles: true\n</code></pre>"},{"location":"tasks/#load-data-from-a-dataset","title":"Load data from a dataset","text":"<pre><code>name: artifact_example\ntasks:\n- name: artifact_task\nexecutor:\n!pipEnv\ncommand: python artifacts.py\ndataSets:\n- ref:\nname: somedataset\nproject: anotherproject\nartifacts:\nsaveChangedFiles: true\n</code></pre>"},{"location":"tasks/#task-reference","title":"Task reference","text":"<p>Tasks can reference other Tasks. This is intended for usecases where inlining a Task is cumbersome for example when adding a model training Task or a Task pipeline. </p>"},{"location":"tasks/#quick-examples_3","title":"Quick examples","text":""},{"location":"tasks/#referencing-a-task-for-model-training","title":"Referencing a Task for model training","text":"<pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask: # Remember this field expects a Task\ntaskRef: train_my_model # This is considered a complete Task\ntasks:\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>Alternatively if we were to inline the Task it would look like:</p> <pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask:\nname: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"tasks/#referencing-a-task-from-a-task","title":"Referencing a Task from a Task","text":"<pre><code># main project ame.yml\nproject: xgboost_project\nmodels:\n- name: product_recommendor\ntraining:\ntask:\ntaskRef: train_my_model tasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre> <p>Currently it is not supported to reference a Task from a different project but that is likely to be implemented in some form in the near future </p>"},{"location":"tasks/#triggering-tasks","title":"Triggering Tasks","text":"<p>For some usecases it might be required to automatically kick off a Task. If you are working with a high level construct such as a dataset or Model we recommended that you first check if it has a mechanism that suits your needs as AME can often help you do less work that way. For example a Model automatically keep deployment up to date and trigger validation before  deployming any new versions. Doing this manually would be non trivial. If you have a need not already covered read on.</p> <p>The main mechanism of triggering independent Tasks is time based. We will be implementing more triggers for example git based triggers in the coming release.</p> <p>In order to have a Task triggered on some recurring basis two things are required. A project with that Task must be present in an AME cluster and the desired Task must have the trigger field configured.</p>"},{"location":"tasks/#quick-examples_4","title":"Quick examples","text":""},{"location":"tasks/#trigger-task-with-cron-schedule","title":"Trigger Task with cron schedule","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: my_task\ntaskRef: train_my_model\n- name: train_my_model\nfromTemplate: shared_templates.xgboost_resources\ntriggers:\nschedule: ***** # TODO some cron schedule\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"tasks/#dags","title":"DAGS","text":""},{"location":"tasks/#working-with-tasks","title":"Working with Tasks","text":""},{"location":"tasks/#pipelines","title":"Pipelines","text":"<p>A task can consist of sub tasks.</p>"},{"location":"tasks/#quick-examples_5","title":"Quick examples","text":""},{"location":"tasks/#pipeline-with-inline-sequential-tasks","title":"Pipeline with inline sequential tasks","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- name: preprocessing executor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"tasks/#pipeline-with-equential-tasks-referenced","title":"Pipeline with equential tasks referenced","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- taskref: preprocessing\n- taskref: training\n- name: preprocessing\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"tasks/#pipeline-with-parallel-tasks","title":"Pipeline with parallel tasks","text":"<pre><code># main project ame.yml\nproject: xgboost_project\ntasks:\n- name: other_task # TODO: how do we handle names for Tasks with a reference.\ntaskRef: train_my_model\n- name: train_my_model\npipeline:\n- - taskref: prepare_dataset_one - taskref: prepare_datast_two - taskref: training\n- name: prepare_dataset_one\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data_one.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: prepare_dataset_two\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python prepare_data_two.py\nresources:\nmemory: 4G cpu: 2 storage: 30G - name: training\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G cpu: 4 storage: 30G nvidia.com/gpu: 1 </code></pre>"},{"location":"tasks/#environment-variables","title":"Environment variables","text":"<p>Environment variable can be set with the <code>environment</code> field. The field accepts a list of key value pairs, see the example below.</p> <p>Note that there are a few environment variables set by AME, future releases of AME will return an error if you attempt to override them, see this (issue)[]. </p> <pre><code># Provided environment variables\n# TODO fill this out\nMLFLOW...\n</code></pre> <p>Quick example</p> <pre><code># ame.yml\ntasks:\n- name: train_my_model\nexecutor:\n!poetry\npythonVersion: 3.11\ncommand: python train.py\nresources:\nmemory: 10G # 10 Gigabyte ram\ncpu: 4 # 4 CPU threads\nstorage: 30G # 30Gigabyte of disk space\nnvidia.com/gpu: 1 # 1 Nvidia GPU\nenvironment:\n# inject environment variable SOME_VAR=SOME_VAL\n- key: SOME_VAR\nval: SOME_VAL\n</code></pre>"},{"location":"tasks/#techinical-details-of-tasks","title":"Techinical details of Tasks","text":""}]}